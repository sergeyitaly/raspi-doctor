install ollama:

wget https://github.com/ollama/ollama/releases/download/v0.11.6/ollama-linux-arm64.tgz -O ollama-linux-arm64.tgz
# Extract it
tar -xvzf ollama-linux-arm64.tgz

# This should create an 'ollama' binary in the current folder
ls -l

# Move the extracted files to the correct system locations
sudo mv bin/ollama /usr/local/bin/
sudo mv lib/ollama /usr/local/lib/

# Set proper permissions
sudo chmod +x /usr/local/bin/ollama
sudo chown -R root:root /usr/local/lib/ollama

# Clean up the downloaded files
rm -rf ollama-linux-arm64.tgz bin lib

# Create the Ollama user and directory structure
sudo useradd -r -s /bin/false ollama
sudo mkdir -p /usr/local/share/ollama/.ollama/models
sudo chown -R ollama:ollama /usr/local/share/ollama

# Create the necessary directories
mkdir -p ~/.ollama/models

# Start Ollama server in the background
nohup ollama serve > ~/ollama_server.log 2>&1 &



# Pull a lightweight model (choose one)
ollama pull tinyllama  # ~600MB - good for testing
ollama pull phi3:mini  # ~1.8GB - better quality

# Test
ollama --version
ollama pull tinyllama
ollama pull phi
ollama run tinyllama

sudo apt install smartmontools
sudo smartctl -a /dev/mmcblk0


chmod +x /opt/pi-health-ai/setup_pi_doctor.sh
sudo /opt/pi-health-ai/setup_pi_doctor.sh
sudo systemctl status collect_health.timer raspi_doctor.timer netcheck.timer secscan.timer

sudo chown -R pi:pi /var/log/ai_health/
sudo chmod -R 755 /var/log/ai_health/





On MACOS .....
brew install osx-cpu-temp
sudo chmod +x ./setup_mac_doctor.sh
./setup_mac_doctor


in .env file locate OLLAMA_MODEL=tinyllama or the other model you prefer like phi3:mini